{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b9486b-e956-4c4c-8c55-c3fa6b6ff8c2",
   "metadata": {},
   "source": [
    "# Counting, proofreading and visualizing inputs and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9467e1",
   "metadata": {},
   "source": [
    "This notebook requires an environment where the python <a href=\"https://navis.readthedocs.io/en/latest/\" target=\"_blank\">navis</a> and <a href=\"https://fafbseg-py.readthedocs.io/en/latest/source/api.html\" target=\"_blank\">fafbseq</a> packages are installed, apart from other well-known packages listed in the import below.\n",
    "<br>**CONTAINS:**\n",
    "<br>A) Analysis of inputs and ouputs based on *cleft score* value\n",
    "<br>B) Analysis of inputs and outputs of a list of neurons\n",
    "<br>C) Proofreading predicted synapses via annotations\n",
    "<br>D) Calculating and plotting synaptic cleft size ditribution between partners \n",
    "<br>E) Checking the existance of IDs from Codex in our data base \n",
    "<br>F) Updating your IDs\n",
    "<br>G) Plotting our Tm9 patches / clusters\n",
    "<br>H) Tm9-patch mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b21e0e-1f30-4651-ae6a-4c5f8db25503",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f963450-3432-4ab4-9063-4ca68f7b5fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import navis\n",
    "import fafbseg\n",
    "from fafbseg import flywire\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from caveclient import CAVEclient\n",
    "from visualizations.helpers.synapse_queries import combine_xyz, separate_xyz, synapse_count\n",
    "\n",
    "client = CAVEclient('flywire_fafb_production')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d853f9-9ceb-41a6-b1f9-9a51704fad79",
   "metadata": {},
   "source": [
    "#### Setting a \"secret\" for accessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416e869-67c2-4e8c-9a74-152f45405367",
   "metadata": {},
   "source": [
    "To get your personal secret, please go to: <a href=\"https://fafbseg-py.readthedocs.io/en/latest/source/tutorials/flywire_secret.html\" target=\"_blank\">get my secret.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325ff7c-a388-4923-880f-3d86536e1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fafbseg.flywire.set_chunkedgraph_secret(\"5719b2db462d94d6aa0e903c1ff889e4\") # 2022.03.11\n",
    "# fafbseg.flywire.set_chunkedgraph_secret(\"c161f679dd3d52b1d5fc19f62cdd0164\") # 2022.04.11 \n",
    "fafbseg.flywire.set_chunkedgraph_secret(\"0c0edb71c5682a971dbadc37bcbabf29\") # 2022.06.21 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33aa50-f643-453b-8127-aaec97d867d5",
   "metadata": {},
   "source": [
    "## A) Analysis of inputs and ouputs based on *cleft score* value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ad980-263d-4f97-b124-3e1d87627428",
   "metadata": {},
   "source": [
    "To automatically detect of pre- and postsynaptic sites, the algorithm used in <a href=\"https://www.nature.com/articles/s41592-021-01183-7\" target=\"_blank\">Buhman et al. 2021.</a>\n",
    "<br>A visualization of all predicted synapses can visualized by Neuroglancer <a href=\"http://www.tinyurl.com/tdq6xkw\" target=\"_blank\">here.</a>\n",
    "<br>The algorithm returns a list of connections with two scores: the cleft score and the connection score. Number of detected synapses depend on them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb36e6-3dc2-4365-8b30-740708ffae5b",
   "metadata": {},
   "source": [
    "<font size=\"4\"> The *cleft score* matters, the *connection score* not that much:</font> <br/>\n",
    "<span style=\"color:blue\">&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; True positives </span> <br/>\n",
    "<span style=\"color:Chocolate\">&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; False positives </span> <br/>\n",
    "<span style=\"color:DimGrey\">&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Unkown </span> <br/>\n",
    "\n",
    "\n",
    "<img src=\"./Images/proofreading/szi-chieh_labels_synapse_eval_cleft_score.png\" \n",
    "     alt=\"cleft_score\"\n",
    "     width=\"300\" height=\"300\" style=\"float: left ; width: 40%; padding-left: 10%\"/>\n",
    "<img src=\"./Images/proofreading/szi-chieh_labels_synapse_eval_synful_score.png\" \n",
    "     alt=\"connection_score\"\n",
    "     width=\"300\" height=\"300\" style=\"float: left ; width: 40%; padding-left: 0%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df172fb1-f8fd-45ee-b182-8ae3af920695",
   "metadata": {},
   "source": [
    "### Testing different cleft score values in Tm9 inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521cd23-7ccb-4c40-ba39-c596b895411c",
   "metadata": {},
   "source": [
    "In the following cells, we choose different *cleft score* values to get the total number of inputs and outputs of a single Tm9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325071f-af23-4ac2-8672-d3a336617315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting inputs and outputs for one neuron with different min_score values\n",
    "\n",
    "# FIRST, Check if root IDs are outdated (i.e. have more recent edits)\n",
    "r1 = 720575940626482442 # root ID query for Tm9\n",
    "print(f'ID up-to-date in FlyWire: {flywire.is_latest_root([r1])}')\n",
    "# SECOND, proceed getting the neurons data if the ID is up to date\n",
    "if flywire.is_latest_root([r1])[0]:\n",
    "    neuron = flywire.get_mesh_neuron(r1) # mesh query\n",
    "else:\n",
    "    print(f'ID not up to date. Update it and run again')\n",
    "\n",
    "# THIRD, proceed getting the neuron's inputs and outputs for a list of different min_scores \n",
    "# “Cleft score” for automatic synaptic detection, Buhmann et al., 2021\n",
    "if flywire.is_latest_root([r1])[0]:\n",
    "    min_score_ls = [0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180]\n",
    "    in_count_ls =[]\n",
    "    out_count_ls =[]\n",
    "    pre_count_ls=[]\n",
    "    post_count_ls=[]\n",
    "    \n",
    "    for score in min_score_ls:\n",
    "        # Fetch the neuron's inputs and ouputs\n",
    "        inputs = flywire.synapses.fetch_synapses(neuron, pre=False, post=True, attach=True, \n",
    "                                                 min_score=score, clean=True, transmitters=False, \n",
    "                                                 neuropils=True, live_query=True, batch_size=30, \n",
    "                                                 dataset='production', progress=True)\n",
    "        outputs = flywire.synapses.fetch_synapses(neuron, pre=True, post=False, attach=True, \n",
    "                                                 min_score=score, clean=True, transmitters=False, \n",
    "                                                 neuropils=True, live_query=True, batch_size=30, \n",
    "                                                 dataset='production', progress=True)\n",
    "        \n",
    "        # Counting inputs and ouputs per ID\n",
    "        inputs_count = {}\n",
    "        inputs_str = inputs.applymap(str)\n",
    "        for c in inputs_str['pre'].to_list():\n",
    "            inputs_count[c] = inputs_count.get(c, 0) + 1\n",
    "        input_count_df = pd.DataFrame(inputs_count, index=[0])\n",
    "        input_count_df = input_count_df.T\n",
    "        input_count_df.rename(columns={0: \"counts\"},inplace=True)\n",
    "        input_count_df.index.names = ['presynaptic_ID']\n",
    "        input_count_df['postsynaptic_ID'] = inputs_str['post'].to_list()[0:len(input_count_df)]\n",
    "        \n",
    "\n",
    "        outputs_count = {}\n",
    "        outputs_str = outputs.applymap(str)\n",
    "        for c in outputs_str['post'].to_list():\n",
    "            outputs_count[c] = outputs_count.get(c, 0) + 1\n",
    "        output_count_df = pd.DataFrame(outputs_count, index=[0])\n",
    "        output_count_df = output_count_df.T\n",
    "        output_count_df.rename(columns={0: \"counts\"},inplace=True)\n",
    "        output_count_df.index.names = ['postsynaptic_ID']\n",
    "        output_count_df['presynaptic_ID'] = outputs_str['pre'].to_list()[0:len(output_count_df)]\n",
    "        \n",
    "        #Storing useful info during the for-loop\n",
    "        in_count_ls.append(input_count_df['counts'].sum())\n",
    "        out_count_ls.append(output_count_df['counts'].sum())\n",
    "        pre_count_ls.append(len(input_count_df.index))\n",
    "        post_count_ls.append(len(output_count_df.index))\n",
    "        \n",
    "        # Printing useful info\n",
    "        #print(f\"Current score = {score}\")\n",
    "        #print(f\"Total number of inputs = {input_count_df['counts'].sum()}\")\n",
    "        #print(f\"Total number of outputs = {output_count_df['counts'].sum()}\")\n",
    "        #print(f\"Total number of presynaptic partners = {len(input_count_df.index)}\")\n",
    "        #print(f\"Total number of postsynaptic partners = {len(output_count_df.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca3db8-77de-438d-96c7-911f61698274",
   "metadata": {},
   "source": [
    "Let's now creat a pandas dataframe with the obtain lists and then generate some line plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfeba1d-d780-4eb8-884d-e5c27ed57d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generation of pandas dataframe from lists\n",
    "cleft_score_df = pd.DataFrame(list(zip(min_score_ls, in_count_ls, out_count_ls, pre_count_ls, post_count_ls)),\n",
    "               columns =['Cleft_scores', 'input_count', 'output_count','pre_partner_count', 'post_partner_count'])\n",
    "#print(cleft_score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2504277-4b2d-4678-ac70-4688f828866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:blue'\n",
    "ax1.plot(cleft_score_df['Cleft_scores'],cleft_score_df['input_count'], color=color)\n",
    "    ax1.set_ylabel('inputs', color=color) \n",
    "    ax1.set_title('Inputs and outputs across cleft scores')\n",
    "    ax1.set_xlabel('minimun cleft score')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('outputs', color=color)  \n",
    "ax2.plot(cleft_score_df['Cleft_scores'],cleft_score_df['output_count'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657369e-49d2-407b-a5bc-c2362faeeeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80073b-be47-4d85-9b32-568df02ce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving excel files\n",
    "# Setting variable\n",
    "outDir = r'Z:\\Connectomics data\\FlyWire\\Excels\\min_score_50'\n",
    "save_excel_file = False\n",
    "\n",
    "if save_excel_file: \n",
    "    ## Inputs\n",
    "    file_name = str(neuron.id)+'_inputs.xlsx'\n",
    "    savePath = os.path.join(outDir, file_name)\n",
    "    inputs_str = inputs.applymap(str)\n",
    "    inputs_str.to_excel(savePath)\n",
    "\n",
    "    file_name = str(neuron.id)+'_inputs_count.xlsx'\n",
    "    savePath = os.path.join(outDir, file_name)\n",
    "    input_count_str_df = input_count_df.applymap(str)\n",
    "    input_count_str_df.to_excel(savePath)\n",
    "\n",
    "\n",
    "    ## Outputs\n",
    "    file_name = str(neuron.id)+'_outputs.xlsx'\n",
    "    savePath = os.path.join(outDir, file_name)\n",
    "    outputs_str = outputs.applymap(str)\n",
    "    outputs_str.to_excel(savePath)\n",
    "\n",
    "    file_name = str(neuron.id)+'_outputs_count.xlsx'\n",
    "    savePath = os.path.join(outDir, file_name)\n",
    "    output_count_str_df = output_count_df.applymap(str)\n",
    "    output_count_str_df.to_excel(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf6fd0-bdd0-42b1-b490-ad07640ae4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52648bfe-6686-43b2-acd8-fe2c3aba0a8b",
   "metadata": {},
   "source": [
    "## B) Analysis of inputs and outputs of a list of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b11f82",
   "metadata": {},
   "source": [
    "### 1. Loading IDs manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94e02b-34be-4767-8833-77839623e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if root IDs are outdated (i.e. have more recent edits)\n",
    "# Selecting Neurons\n",
    "curr_ID_ls = [720575940623883277\n",
    ",720575940610269508\n",
    ",720575940629782335\n",
    ",720575940629271370]   # Remaining Tm1 to proofread for sparse selection of L optic lobe\n",
    "\n",
    "print(f'ID up-to-date in FlyWire: {flywire.is_latest_root(curr_ID_ls)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e22df",
   "metadata": {},
   "source": [
    "#### 1.1 Cheking connectivity of not-up-to-date segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6554910",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not np.unique(flywire.is_latest_root(curr_ID_ls))[0]: #if not up-to-date\n",
    "    # Fetch the neuron's inputs and outputs\n",
    "    neurons_inputs = flywire.synapses.fetch_synapses(curr_ID_ls, pre=False, post=True, attach=True, \n",
    "                                             min_score=50, clean=True, transmitters=False, \n",
    "                                             neuropils=True, batch_size=30, \n",
    "                                             dataset='production', progress=True) #,mat= \"live\"\n",
    "    neurons_outputs = flywire.synapses.fetch_synapses(curr_ID_ls, pre=True, post=False, attach=True, \n",
    "                                             min_score=50, clean=True, transmitters=False, \n",
    "                                             neuropils=True, batch_size=30, \n",
    "                                             dataset='production', progress=True) #, mat= \"live\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94868116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "683eecd3",
   "metadata": {},
   "source": [
    "### 1. Or, loading from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2828bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose path and file\n",
    "import os\n",
    "\n",
    "dataPath = r'D:\\Connectomics data\\FlyWire\\Excels'\n",
    "dataPath = r'C:\\Users\\sebas\\Downloads'\n",
    "fileDate = '20230110'\n",
    "fileName = f'Tm9 proofreadings_{fileDate}.xlsx'\n",
    "fileName = f'Tm1 proofreadings_{fileDate}.xlsx'\n",
    "filePath = os.path.join(dataPath,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(filePath)\n",
    "curr_ID_ls = df[\"seg_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying any filter?\n",
    "filtered_df = df[(df['twigs proofread (Y/N)']== 'Y') & (df['inputs_proofread (Y/N)']!= 'Y') & (df['cluster_id']!= -1)& (df['cluster_id']!= 3)].copy()\n",
    "print(len(filtered_df))\n",
    "\n",
    "# Defining id to work with\n",
    "curr_ID_ls = filtered_df[\"seg_id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8e0a2",
   "metadata": {},
   "source": [
    "### 1. Or, loading from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose path and file\n",
    "import os\n",
    "\n",
    "dataPath = r'E:\\Connectomics-Data\\FlyWire\\Txts\\cell_type_proofread'\n",
    "fileDate = '20230614'\n",
    "fileName = f'root_ids_Tm16_side_right.txt'\n",
    "filePath = os.path.join(dataPath,fileName)\n",
    "ids_df = pd.read_csv(filePath, sep = \",\")\n",
    "curr_ID_ls = ids_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78dc606",
   "metadata": {},
   "source": [
    "### 2. Updating IDs and fetching synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the IDs via Fafbseg\n",
    "updated_ID_df = fafbseg.flywire.update_ids(curr_ID_ls, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de722a-b4e8-4e1c-9afd-445dd8607737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching synapses from new IDs\n",
    "ID_ls = updated_ID_df[\"new_id\"].tolist()\n",
    "\n",
    "if np.unique(flywire.is_latest_root(ID_ls))[0]:\n",
    "    # Fetch the neuron's inputs and putputs\n",
    "    neurons_inputs = flywire.synapses.fetch_synapses(ID_ls, pre=False, post=True, attach=True, \n",
    "                                             min_score=50, clean=True, transmitters=False, \n",
    "                                             neuropils=True, batch_size=30, \n",
    "                                             dataset='production', progress=True,mat= \"live\")\n",
    "    neurons_outputs = flywire.synapses.fetch_synapses(ID_ls, pre=True, post=False, attach=True, \n",
    "                                             min_score=50, clean=True, transmitters=False, \n",
    "                                             neuropils=True, batch_size=30, \n",
    "                                             dataset='production', progress=True, mat= \"live\")\n",
    "    #synaptic_counts = flywire.synapses.synapse_counts(root_ids, by_neuropil=False, min_score=30, live_query=True,batch_size=10, dataset='production')\n",
    "else:\n",
    "    print(f'IDs not up to date, analysis aborted') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52d8ea-1c68-4303-ab06-bdda32124561",
   "metadata": {},
   "source": [
    "#### Selecting a neuropile of interest for synaptic counts per neuron ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c99376",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07007581-c8da-446b-9669-f9148f8d1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting inputs from a single neuropile\n",
    "neuropile = ['ME_R','ME_R'] # String. 'LO_R', 'ME_R', ...\n",
    "#or\n",
    "neuropile_list = ['ME_R','LO_R']\n",
    "\n",
    "neuropile_neurons_inputs = neurons_inputs[(neurons_inputs['neuropil'].isin(neuropile_list))]\n",
    "no_neuropile_neurons_inputs = neurons_inputs[~(neurons_inputs['neuropil'].isin(neuropile))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46674d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_neuropile_neurons_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35007d22",
   "metadata": {},
   "source": [
    "### 2.1. For all inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bbf4f-2728-4f46-b1b8-6bc03406834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOPING. Counting inputs and ouputs per ID, option joining dataframes\n",
    "final_input_df = pd.DataFrame()\n",
    "for n in neurons_inputs['post'].unique():\n",
    "    inputs_count = {}\n",
    "    curr_inputs = neurons_inputs[neurons_inputs['post'] == n]\n",
    "    inputs_str = curr_inputs.applymap(str)\n",
    "    \n",
    "    for c in inputs_str['pre'].to_list():\n",
    "        inputs_count[c] = inputs_count.get(c, 0) + 1\n",
    "    input_count_df = pd.DataFrame(inputs_count, index=[0])\n",
    "    input_count_df = input_count_df.T\n",
    "    input_count_df.rename(columns={0: \"counts\"},inplace=True)\n",
    "    input_count_df.index.names = ['presynaptic_ID']\n",
    "    input_count_df = input_count_df.sort_values(by=\"counts\",ascending=False)\n",
    "    input_count_df['postsynaptic_ID'] = inputs_str['post'].to_list()[0:len(input_count_df)]\n",
    "    final_input_df = final_input_df.append(input_count_df)\n",
    "    #print(f'Counting done for: {n}')\n",
    "input_count_str_df = final_input_df.applymap(str)\n",
    "input_count_str_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d77e7",
   "metadata": {},
   "source": [
    "### 2.2 Or, for a selection of all inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOPING. Counting inputs and ouputs per ID, option joining dataframes\n",
    "#For \"no_neuropile_neurons_inputs\"\n",
    "\n",
    "final_input_df = pd.DataFrame()\n",
    "for n in no_neuropile_neurons_inputs['post'].unique():\n",
    "    inputs_count = {}\n",
    "    curr_inputs = no_neuropile_neurons_inputs[no_neuropile_neurons_inputs['post'] == n]\n",
    "    inputs_str = curr_inputs.applymap(str)\n",
    "    \n",
    "    for c in inputs_str['pre'].to_list():\n",
    "        inputs_count[c] = inputs_count.get(c, 0) + 1\n",
    "    input_count_df = pd.DataFrame(inputs_count, index=[0])\n",
    "    input_count_df = input_count_df.T\n",
    "    input_count_df.rename(columns={0: \"counts\"},inplace=True)\n",
    "    input_count_df.index.names = ['presynaptic_ID']\n",
    "    input_count_df = input_count_df.sort_values(by=\"counts\",ascending=False)\n",
    "    input_count_df['postsynaptic_ID'] = inputs_str['post'].to_list()[0:len(input_count_df)]\n",
    "    final_input_df = final_input_df.append(input_count_df)\n",
    "    #print(f'Counting done for: {n}')\n",
    "input_count_str_df = final_input_df.applymap(str)\n",
    "input_count_str_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490a358",
   "metadata": {},
   "source": [
    "### 2.3. For all outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e196cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOPING. Counting outputs and ouputs per ID, option joining dataframes\n",
    "final_output_df = pd.DataFrame()\n",
    "for n in neurons_outputs['pre'].unique():\n",
    "    outputs_count = {}\n",
    "    curr_outputs = neurons_outputs[neurons_outputs['pre'] == n]\n",
    "    outputs_str = curr_outputs.applymap(str)\n",
    "    \n",
    "    for c in outputs_str['post'].to_list():\n",
    "        outputs_count[c] = outputs_count.get(c, 0) + 1\n",
    "    output_count_df = pd.DataFrame(outputs_count, index=[0])\n",
    "    output_count_df = output_count_df.T\n",
    "    output_count_df.rename(columns={0: \"counts\"},inplace=True)\n",
    "    output_count_df.index.names = ['postsynaptic_ID']\n",
    "    output_count_df = output_count_df.sort_values(by=\"counts\",ascending=False)\n",
    "    output_count_df['presynaptic_ID'] = outputs_str['pre'].to_list()[0:len(output_count_df)]\n",
    "    final_output_df = final_output_df.append(output_count_df)\n",
    "    #print(f'Counting done for: {n}')\n",
    "output_count_str_df = final_output_df.applymap(str)\n",
    "output_count_str_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff54919f",
   "metadata": {},
   "source": [
    "### 3. Adding useful information to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting dataframe\n",
    "partner_ID = input_count_str_df.index.tolist()\n",
    "#partner_ID = output_count_str_df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the IDs via Fafbseg\n",
    "\n",
    "updated_ID_df = fafbseg.flywire.update_ids(partner_ID, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "\n",
    "partner_ID_ls = updated_ID_df[\"new_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying user-based annotations about cell identity\n",
    "\n",
    "identification_df = flywire.find_celltypes(partner_ID_ls, user=None, exact=False, case=False, regex=True, update_roots=False)\n",
    "identification_no_duplicates_df = identification_df.drop_duplicates(subset='pt_root_id', keep='last', inplace=False, ignore_index=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "identification_no_duplicates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding info to the current data set. The function:\n",
    "\n",
    "def update_dataframe_single_column(source_df, target_df, reference_column):\n",
    "    # Create a dictionary mapping from the reference column to the source DataFrame\n",
    "    reference_dict = source_df.groupby(reference_column).first().reset_index().to_dict(orient='records')\n",
    "    reference_dict = {row[reference_column]: row for row in reference_dict}\n",
    "\n",
    "    # Update the target DataFrame based on the reference column\n",
    "    for i, row in target_df.iterrows():\n",
    "        ref = row[reference_column]\n",
    "        if ref in reference_dict:\n",
    "            source_row = reference_dict[ref]\n",
    "            target_df.loc[i] = source_row\n",
    "\n",
    "    return target_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only for inputs\n",
    "\n",
    "\n",
    "# Selecting dataframes and resetting index\n",
    "source_df = identification_no_duplicates_df.copy()\n",
    "source_df.reset_index(inplace = True, drop = True)\n",
    "target_df = input_count_str_df.copy()\n",
    "target_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "# Adding columns for the function to properly work\n",
    "target_df['partner_ID'] = input_count_str_df.index.astype(str)\n",
    "source_df['partner_ID'] = identification_no_duplicates_df['pt_root_id'].tolist()\n",
    "target_df['name'] = None\n",
    "source_df['name'] = identification_no_duplicates_df['tag'].tolist()\n",
    "target_df['author'] = None\n",
    "source_df['author'] = identification_no_duplicates_df['user_id'].tolist()\n",
    "\n",
    "# Function inputs\n",
    "source_cols = ['name', 'author','partner_ID']\n",
    "target_cols = ['name', 'author', 'partner_ID']\n",
    "reference_column = 'partner_ID'\n",
    "\n",
    "source_df = source_df[source_cols].copy()\n",
    "target_df = target_df[source_cols].copy()\n",
    "\n",
    "source_df = source_df.astype(str)\n",
    "target_df = target_df.astype(str)\n",
    "\n",
    "\n",
    "# Running the function and compleating the dataset\n",
    "result_df = update_dataframe_single_column(source_df, target_df,reference_column)\n",
    "result_df['counts'] = input_count_str_df['counts'].tolist()\n",
    "result_df['postsynaptic_ID'] = input_count_str_df['postsynaptic_ID'].tolist()\n",
    "result_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only for outputs\n",
    "\n",
    "\n",
    "# Selecting dataframes and resetting index\n",
    "source_df = identification_no_duplicates_df.copy()\n",
    "source_df.reset_index(inplace = True, drop = True)\n",
    "target_df = output_count_str_df.copy()\n",
    "target_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "# Adding columns for the function to properly work\n",
    "target_df['partner_ID'] = output_count_str_df.index.astype(str)\n",
    "source_df['partner_ID'] = identification_no_duplicates_df['pt_root_id'].tolist()\n",
    "target_df['name'] = None\n",
    "source_df['name'] = identification_no_duplicates_df['tag'].tolist()\n",
    "target_df['author'] = None\n",
    "source_df['author'] = identification_no_duplicates_df['user_id'].tolist()\n",
    "\n",
    "# Function inputs\n",
    "source_cols = ['name', 'author','partner_ID']\n",
    "target_cols = ['name', 'author', 'partner_ID']\n",
    "reference_column = 'partner_ID'\n",
    "\n",
    "source_df = source_df[source_cols].copy()\n",
    "target_df = target_df[source_cols].copy()\n",
    "\n",
    "source_df = source_df.astype(str)\n",
    "target_df = target_df.astype(str)\n",
    "\n",
    "\n",
    "# Running the function and compleating the dataset\n",
    "result_df = update_dataframe_single_column(source_df, target_df,reference_column)\n",
    "result_df['counts'] = output_count_str_df['counts'].tolist()\n",
    "result_df['presynaptic_ID'] = output_count_str_df['presynaptic_ID'].tolist()\n",
    "result_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5f85a-55f8-4915-80d8-85b31e6c1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data in your computer\n",
    "outDir = r'E:\\Connectomics-Data\\FlyWire\\Excels\\min-score-50'\n",
    "save_excel_file = True\n",
    "\n",
    "if save_excel_file: \n",
    "    ## Input count\n",
    "    #file_name = f'Tm16_neurons_output_count_R.xlsx'\n",
    "    file_name = f'Tm1_neurons_input_count_L_remaining_4.xlsx'\n",
    "    savePath = os.path.join(outDir, file_name)\n",
    "    result_df.to_excel(savePath, sheet_name='Buhmann synapses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving more data in the same file\n",
    "from openpyxl import load_workbook\n",
    "updated_ID_df_str =  updated_ID_df.applymap(str)\n",
    "filePath = savePath\n",
    "\n",
    "book = load_workbook(filePath)\n",
    "writer = pd.ExcelWriter(filePath, engine = 'openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "updated_ID_df_str.to_excel(writer, sheet_name='ID_update')\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5583bb",
   "metadata": {},
   "source": [
    "## C) Proofreading predicted synapses via annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868c59e-7e1b-4172-a1c5-7fc0f1345b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually loading the URL containing synapses as annotations and notes in each\n",
    "\n",
    "URL = 'https://ngl.flywire.ai/?json_url=https://global.daf-apis.com/nglstate/api/v1/5833034053976064'\n",
    "dict_URL = fafbseg.flywire.decode_url(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f57a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debuggin purposes\n",
    "\n",
    "#URL = 'https://ngl.flywire.ai/?json_url=https://global.daf-apis.com/nglstate/api/v1/5574105810075648'# OLD URL\n",
    "#URL = 'https://ngl.flywire.ai/?json_url=https://global.daf-apis.com/nglstate/api/v1/6667315345096704'# UPDATED URL\n",
    "URL = 'https://ngl.flywire.ai/?json_url=https://global.daf-apis.com/nglstate/api/v1/6516888544739328' # No segments in the dict\n",
    "dict_URL = fafbseg.flywire.decode_url(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5046e",
   "metadata": {},
   "source": [
    "### 1. Loading URLs from excell file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the URLs from an excel file\n",
    "\n",
    "# Choose path and file\n",
    "dataPath = r'C:\\Users\\sebas\\Downloads'\n",
    "fileName = 'All_Tm9_neurons_input_count_ME_R_20221017.xlsx'\n",
    "filePath = os.path.join(dataPath,fileName)\n",
    "\n",
    "df = pd.read_excel(filePath)\n",
    "\n",
    "URL_ls = df['URL buhmann postsynapses']\n",
    "\n",
    "#URL_ls =['https://ngl.flywire.ai/?json_url=https://global.daf-apis.com/nglstate/api/v1/5833034053976064','https://ngl.flywire.ai/?json_url=https://global.daf-apis.com/nglstate/api/v1/6635071146557440']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b9329",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_ls = URL_ls[URL_ls.notnull()] # Getting rid of NaNs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c14fb",
   "metadata": {},
   "source": [
    "### 2. Extracting annotations' labels / comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5767fb2-ec02-4f3e-9422-bb57cc51240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting points and labels/descriptions\n",
    "points = []\n",
    "descriptions = []\n",
    "segment_ids = []\n",
    "faulty_URLs = []\n",
    "\n",
    "for URL in URL_ls:\n",
    "    dict_URL = fafbseg.flywire.decode_url(URL)\n",
    "    for ann in dict_URL['annotations']:\n",
    "        if 'point' in ann.keys():\n",
    "            try: \n",
    "                segment_ids.append(ann['segments'])\n",
    "            except:# dealing with faulty URLs with no data inside\n",
    "                faulty_URLs.append(URL)\n",
    "                continue\n",
    "            try:\n",
    "                descriptions.append(ann['description'])\n",
    "            except: # dealing with faulty URLs with no data inside\n",
    "                descriptions.append('NO DESCRIPTION YET')\n",
    "        \n",
    "            points.append(ann['point'])\n",
    "            \n",
    "# Splitting in pre and post IDs\n",
    "pre = []\n",
    "post = []\n",
    "for pair in segment_ids:\n",
    "    pre.append(pair[0])\n",
    "    post.append(pair[1])   \n",
    "    \n",
    "#  len([d for d in descriptions if d.lower() == 'true' or d.lower() == 'true\\n' ]) # Brief count of true synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fd4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the summary data frame\n",
    "proofread_synapses_df = pd.DataFrame()\n",
    "\n",
    "proofread_synapses_df['post_pt_position'] = points\n",
    "proofread_synapses_df['proofread_label'] = descriptions\n",
    "proofread_synapses_df['pre_id'] = pre\n",
    "proofread_synapses_df['post_id'] = post\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there was any faulta URL\n",
    "faulty_URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4233deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize your current annotation table\n",
    "proofread_synapses_df[proofread_synapses_df['proofread_label']!= 'NO DESCRIPTION YET'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1064d",
   "metadata": {},
   "source": [
    "### 3. Quantifiying and showing annotation proofread status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current total number of synapses proofread as TRUE from all links in the file:\n",
    "len([d for d in descriptions if d.lower() == 'true' or d.lower() == 'true\\n' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current total number of synapses proofread as FALSE from all links in the file:\n",
    "len([d for d in descriptions if d.lower() == 'false' or d.lower() == 'false\\n' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current total number of synapses proofread as FALSE NEGATIVE from all links in the file:\n",
    "len([d for d in descriptions if d.lower() == 'false negative' or d.lower() == 'false negative\\n' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731a030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e51f8a5",
   "metadata": {},
   "source": [
    "### 4. Comparing annotation points from 2 URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare number as well as XYZ location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbdbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2570f33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e19f1f1",
   "metadata": {},
   "source": [
    "## D) Calculating and plotting synaptic cleft size ditribution between partners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596905ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE DONE\n",
    "# 1. Load Tm9 ID's from excel file. \n",
    "# 2. Get main input (probably L3)\n",
    "# 3. Get individual synapses (pre and post sites)\n",
    "# 4. Calculate the distance between the two points\n",
    "# 5. Plot the distance ditribition for a given Tm9-L3 pair\n",
    "# 6. Plot the median of all Tm9-L3 distribution as a distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680e558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b3ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49e07eea",
   "metadata": {},
   "source": [
    "## E) Checking the existance of IDs from Codex in our data base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Codex file\n",
    "\n",
    "# Choose path and file\n",
    "dataPath = r'C:\\Users\\sebas\\Downloads'\n",
    "fileName = 'root_ids_Tm9_447.txt'\n",
    "filePath = os.path.join(dataPath,fileName)\n",
    "\n",
    "#Read txt file\n",
    "from numpy import loadtxt\n",
    "codex_ID_ls = list(loadtxt(filePath, comments=\"#\", delimiter=\",\", unpack=False, dtype='str'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading your IDs\n",
    "\n",
    "# Choose path and file\n",
    "dataPath = r'C:\\Users\\sebas\\Downloads'\n",
    "fileName = 'Tm9 proofreadings.xlsx'\n",
    "filePath = os.path.join(dataPath,fileName)\n",
    "df = pd.read_excel(filePath)\n",
    "your_ID_ls = df[\"seg_id\"].astype(str).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updatind IDs using FAFBSEG\n",
    "new_codex_ID_df = flywire.update_ids(codex_ID_ls, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "new_codex_ID_ls = new_codex_ID_df[\"new_id\"].tolist()\n",
    "\n",
    "new_your_ID_df = flywire.update_ids(your_ID_ls, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "new_your_ID_ls = new_your_ID_df[\"new_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f24d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the new IDs in codex ID list with respect to your ID list\n",
    "print(f\"Expected lenght for ID_diference: {len(new_codex_ID_ls)-len(new_your_ID_ls)}\")\n",
    "ID_diference = set(new_codex_ID_ls) - set(new_your_ID_ls)\n",
    "ID_diference_ls = list(ID_diference)\n",
    "print(f\"Current difference: {len(ID_diference_ls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6af04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking in URL\n",
    "old_url = flywire.encode_url(your_ID_ls)\n",
    "print(f'CURRENT old segment IDs: {old_url}')\n",
    "new_url = flywire.encode_url(new_your_ID_ls)\n",
    "print(f'CURRENT new segment IDs: {new_url}')\n",
    "new_url = flywire.encode_url(ID_diference_ls)\n",
    "print(f'ADD segments: {new_url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2280de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, CAVE update not needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf101533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Updating  chunkedgraph module of CAVE\n",
    "# codex_ID_ls_int = list(map(int,codex_ID_ls))\n",
    "# new_codex_ID_ls_int = list(map(client.chunkedgraph.get_latest_roots,codex_ID_ls_int))\n",
    "\n",
    "# your_ID_ls_int = list(map(int,your_ID_ls))\n",
    "# new_your_ID_ls_int = list(map(client.chunkedgraph.get_latest_roots,your_ID_ls_int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0cc926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Checking the new IDs in codex ID list with respect to your ID list\n",
    "# print(f\"Expected lenght for ID_diference: {len(new_codex_ID_ls_int)-len(new_your_ID_ls_int)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Putting the new IDs into a list and getting a new neuroglancer URL\n",
    "# new_your_ID_ls_arr = np.concatenate(new_your_ID_ls_int, axis=0 )\n",
    "# new_your_IDs_ls = new_your_ID_ls_arr.tolist()\n",
    "# old_url = flywire.encode_url(your_IDs_ls)\n",
    "# print(f'OLD segments: {old_url}')\n",
    "# new_url = flywire.encode_url(new_your_IDs_ls)\n",
    "# print(f'NEW segments: {new_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af889d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Putting the new IDs into a list and getting a new neuroglancer URL\n",
    "# new_codex_ID_ls_arr = np.concatenate(new_codex_ID_ls_int, axis=0 )\n",
    "# new_codex_IDs_ls = new_codex_ID_ls_arr.tolist()\n",
    "# old_url = flywire.encode_url(codex_IDs_ls)\n",
    "# print(f'OLD segments: {old_url}')\n",
    "# new_url = flywire.encode_url(new_codex_IDs_ls)\n",
    "# print(f'NEW segments: {new_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd8d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1ac8c85",
   "metadata": {},
   "source": [
    "## F) Updating your IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading your IDs\n",
    "\n",
    "# Choose path and file\n",
    "dataPath = r'C:\\Users\\sebas\\Downloads'\n",
    "fileName = 'Tm9 proofreadings.xlsx'\n",
    "filePath = os.path.join(dataPath,fileName)\n",
    "df = pd.read_excel(filePath)\n",
    "your_ID_ls = df[\"seg_id\"].astype(str).tolist()\n",
    "\n",
    "#Updating the IDs\n",
    "new_your_ID_df = flywire.update_ids(your_ID_ls, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12889f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data in your computer\n",
    "outDir = r'C:\\Users\\sebas\\Downloads'\n",
    "save_excel_file = True\n",
    "new_your_ID_df = new_your_ID_df.astype(str)\n",
    "\n",
    "if save_excel_file: \n",
    "    ## Input count\n",
    "    file_name = f'Update_IDs.xlsx'\n",
    "    savePath = os.path.join(outDir, file_name)\n",
    "    new_your_ID_df.to_excel(savePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657813b",
   "metadata": {},
   "source": [
    "## G) Plotting our Tm9 patches /clusters or neuron types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading your IDs\n",
    "\n",
    "# Choose path and file\n",
    "dataPath = r'C:\\Users\\sebas\\Downloads'\n",
    "fileName = 'Tm9 proofreadings_20221212.xlsx' # For Tm9 pacthes\n",
    "#fileName = 'All_Tm9_neurons_input_count_ME_R_20230110.xlsx' # For neuron types\n",
    "filePath = os.path.join(dataPath,fileName)\n",
    "df = pd.read_excel(filePath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b9769",
   "metadata": {},
   "source": [
    "### 0. Plotting all twig-proofread neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4415e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c46abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "299affae",
   "metadata": {},
   "source": [
    "### 1. Plotting all clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3745a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by cluster ID  and generate a Neuroglancer URL\n",
    "\n",
    "cluster_ids = df[\"cluster_id\"].unique() # For Tm9 patches\n",
    "\n",
    "for c_id in cluster_ids:\n",
    "    temp_df = df[df[\"cluster_id\"] == c_id].copy()\n",
    "    print(f'Number of IDs in cluster {c_id}: {len(temp_df)}')\n",
    "    temp_url = flywire.encode_url(temp_df[\"seg_id\"].tolist())\n",
    "    print(f'Cluster {c_id} URL: {temp_url}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf51e88c",
   "metadata": {},
   "source": [
    "### 1. Or, plotting all neuron types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deletting spaces from symbol strings\n",
    "symbol_no_Spaces = df.symbol.str.strip()\n",
    "df[\"symbol\"] = symbol_no_Spaces\n",
    "guess_no_Spaces = df.guess.str.strip()\n",
    "df[\"guess\"] = guess_no_Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af44890",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_ids = df[\"symbol\"].unique() # For identified inputs\n",
    "guess_ids = df[\"guess\"].unique() # For identified inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6df7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2edc15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating URLs for each neuron type\n",
    "for s_id in symbol_ids:\n",
    "    temp_df = df[df[\"symbol\"] == s_id].copy()\n",
    "    print(f'Repetitions in the data set for {s_id}: {len(temp_df)}')\n",
    "    temp_url = flywire.encode_url(temp_df[\"presynaptic_ID\"].tolist())\n",
    "    print(f'Symbol {s_id} URL: {temp_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b369553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating URLs for each neuron type\n",
    "for g_id in guess_ids:\n",
    "    temp_df = df[df[\"guess\"] == g_id].copy()\n",
    "    print(f'Repetitions in the data set for {g_id}: {len(temp_df)}')\n",
    "    temp_url = flywire.encode_url(temp_df[\"presynaptic_ID\"].tolist())\n",
    "    print(f'Guess {g_id} URL: {temp_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c92b9b",
   "metadata": {},
   "source": [
    "## H) Tm9-patch mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4125a437",
   "metadata": {},
   "source": [
    "### 1.1 Visualizing neuron of interest to mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d7c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load neuron from data base\n",
    "reference_neuron_type = 'Tm16'\n",
    "import os\n",
    "\n",
    "dataPath = r'D:\\Connectomics data\\FlyWire\\Excels'\n",
    "fileDate = '20221216'\n",
    "fileName = f'All_Tm9_neurons_input_count_ME_R_{fileDate}.xlsx'\n",
    "filePath = os.path.join(dataPath,fileName)\n",
    "data_base_df = pd.read_excel(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the dataframe with  the \"reference_neuron_type\"\n",
    "reference_neuron_type_df = data_base_df[data_base_df['symbol'] == reference_neuron_type].copy()\n",
    "# Creting a Neuroglancer view\n",
    "url = flywire.encode_url(reference_neuron_type_df[\"presynaptic_ID\"].tolist())\n",
    "print(f'Neurons URL: {url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bfbaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_neuron_type_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1dac52",
   "metadata": {},
   "source": [
    "### 1.2 Loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea16f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96171ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload all presynaptic inputs for all Tm9 belonging to a patch in a single dataframe\n",
    "#Loading your IDs\n",
    "\n",
    "# Choose path and file\n",
    "import os\n",
    "\n",
    "dataPath = r'D:\\Connectomics data\\FlyWire\\Excels'\n",
    "dataPath = r'C:\\Users\\sebas\\Downloads'\n",
    "fileDate = '20230109'\n",
    "fileName = f'Tm9 proofreadings_{fileDate}.xlsx'\n",
    "filePath = os.path.join(dataPath,fileName)\n",
    "df = pd.read_excel(filePath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d961da5",
   "metadata": {},
   "source": [
    "### 2. Cluster selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting cluster based on cluster ID\n",
    "c_id = 2.0\n",
    "filtered_df = df[df[\"cluster_id\"] == c_id].copy()\n",
    "segmentIDs = filtered_df[\"seg_id\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17becb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the IDs\n",
    "new_segmentIDs_df = flywire.update_ids(segmentIDs, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "new_segmentIDs = new_segmentIDs_df[\"new_id\"].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8912fb",
   "metadata": {},
   "source": [
    "### 3. Finding other Tm9 based on popular presynaptic neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3231d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the common presynapses dataframe (no Buhmann cleft_score filter applied)\n",
    "\n",
    "pre_synapses = flywire.synapses.fetch_synapses(new_segmentIDs, pre=False, post=True, attach=True, \n",
    "                                             min_score=0, clean=True, transmitters=False, \n",
    "                                             neuropils=True, batch_size=30, \n",
    "                                             dataset='production', progress=True,mat= \"live\")\n",
    "post_synapses = flywire.synapses.fetch_synapses(new_segmentIDs, pre=True, post=False, attach=True, \n",
    "                                             min_score=0, clean=True, transmitters=False, \n",
    "                                             neuropils=True, batch_size=30, \n",
    "                                             dataset='production', progress=True,mat= \"live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe9a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting inputs from a single neuropile\n",
    "neuropile = 'ME_R' # String. 'LO_R', 'ME_R', ...\n",
    "neuropile_pre_synapses = pre_synapses[pre_synapses['neuropil'] == neuropile].copy()\n",
    "neuropile_post_synapses = post_synapses[post_synapses['neuropil'] == neuropile].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80b3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting synaptic counts\n",
    "\n",
    "# Using FAFseg function\n",
    "synaptic_counts = fafbseg.flywire.synapses.synapse_counts(new_segmentIDs, by_neuropil=False, \n",
    "                                        min_score=0,mat='live', batch_size=10, dataset='production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a367231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using my own function\n",
    "# Getting synapse_count data frame, among other interesting ones\n",
    "#Combining x,y,z columns for future purposes\n",
    "combine_xyz(pre_synapses) \n",
    "combine_xyz(post_synapses)\n",
    "count_pre, count_post, synapses_count_updated = synapse_count(pre_synapses, post_synapses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(count_pre['presynaptic_ID'].unique()))\n",
    "index = count_pre.index\n",
    "print(len(index.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba660c",
   "metadata": {},
   "source": [
    "### 3.1 Getting the most popular presynaptic partners among the neurons in the patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pair-wise comparisons to find common presynaptic ids and rank them by popularity\n",
    "\n",
    "count_pre.sort_index(ascending=True)\n",
    "index_ids = count_pre.index.unique().tolist()\n",
    "popular_pre_ids_df = pd.DataFrame()\n",
    "for i in range(len(index_ids)):\n",
    "    print(f'Comparing: {index_ids[0]}')\n",
    "    reminding_ids = [s for s in index_ids if s != index_ids[0]]\n",
    "    #Creating reference df to be compared\n",
    "    reference_df = count_pre[count_pre.index == index_ids[0]].copy()\n",
    "    #Pair-wise comparison with other dataframes\n",
    "    common_df = pd.DataFrame()\n",
    "    for r_id in reminding_ids:\n",
    "        compare_to_df = count_pre[count_pre.index == r_id].copy()\n",
    "        curr_comparison_df = reference_df[reference_df['presynaptic_ID'].isin(compare_to_df['presynaptic_ID'])]\n",
    "        data_frames = [common_df, curr_comparison_df]\n",
    "        common_df = pd.concat(data_frames)\n",
    "        popular_pre_ids = common_df['presynaptic_ID'].value_counts()\n",
    "        # Putting together all the pair/wise comparisons in a single dataframe\n",
    "        popular_pre_ids_df = pd.concat([popular_pre_ids_df, popular_pre_ids.to_frame()])\n",
    "        \n",
    "    #Removing the id that has done all comparisons\n",
    "    print(f'Done: {index_ids[0]}')\n",
    "    index_ids.remove(index_ids[0])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popularity rank\n",
    "popular_pre_ids_df.index.value_counts().to_frame(name ='popularity rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing some postsynaptic partners from the most popular Tm9 presynaptic parters to uncover other Tm9s\n",
    "popular_pre_ids = [720575940630334720,720575940631727146,720575940626719065,720575940628005007,720575940623001599,720575940614448746]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9366a38",
   "metadata": {},
   "source": [
    "### 3.2 Connectivity of the popular presynaptic partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d04115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average connectivity with those Tm9s\n",
    "popular_id_count_ls = []\n",
    "for p_id in popular_pre_ids:\n",
    "    \n",
    "    #Retrieve all postsynaptic partners with min cleft_score 50!:\n",
    "    post_synapses = flywire.synapses.fetch_synapses(p_id, pre=True, post=False, attach=True, \n",
    "                                             min_score=50, clean=True, transmitters=False, \n",
    "                                             neuropils=True, batch_size=30, \n",
    "                                             dataset='production', progress=True,mat= \"live\")\n",
    "    post_count_ls = []\n",
    "    for post_id in new_segmentIDs:\n",
    "        temp_post_synapses = post_synapses[post_synapses['post']==post_id].copy()\n",
    "        temp_count = len(temp_post_synapses)\n",
    "        post_count_ls.append(temp_count)\n",
    "    popular_id_count_ls.append(post_count_ls)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614186f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_id_count_ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e5899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For specific popular presynaptic partner, based on counts, retrieve postsynaptic parters where we might find other Tm9s\n",
    "p_id = [720575940614448746]\n",
    "\n",
    "# Synaptic counts\n",
    "pre_synapses = flywire.synapses.fetch_synapses(p_id, pre=False, post=True, attach=True, \n",
    "                                             min_score=50, clean=True, transmitters=False, \n",
    "                                             neuropils=True, batch_size=30, \n",
    "                                             dataset='production', progress=True,mat= \"live\")\n",
    "post_synapses = flywire.synapses.fetch_synapses(p_id, pre=True, post=False, attach=True, \n",
    "                                             min_score=50, clean=True, transmitters=False, \n",
    "                                             neuropils=True, batch_size=30, \n",
    "                                             dataset='production', progress=True,mat= \"live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533509e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neuropile filter\n",
    "# Selecting inputs from a single neuropile\n",
    "neuropile = 'ME_R' # String. 'LO_R', 'ME_R', ...\n",
    "neuropile_pre_synapses = pre_synapses[pre_synapses['neuropil'] == neuropile].copy()\n",
    "neuropile_post_synapses = post_synapses[post_synapses['neuropil'] == neuropile].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using FAFseg function\n",
    "synaptic_counts = fafbseg.flywire.synapses.synapse_counts(p_id, by_neuropil=True, \n",
    "                                        min_score=50,mat='live', batch_size=10, dataset='production')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd93192",
   "metadata": {},
   "outputs": [],
   "source": [
    "synaptic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573445d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using my own function\n",
    "# Getting synapse_count data frame, among other interesting ones\n",
    "#Combining x,y,z columns for future purposes\n",
    "combine_xyz(neuropile_pre_synapses) \n",
    "combine_xyz(neuropile_post_synapses)\n",
    "count_pre, count_post, synapses_count_updated = synapse_count(neuropile_pre_synapses, neuropile_post_synapses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f44b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting postsynaptic dis by filtering connectivity\n",
    "count_post['counts'] = count_post['counts'].astype('int')\n",
    "post_id_ls = count_post[(count_post['counts']>=5) & (count_post['counts']<=8)]['postsynaptic_ID'].tolist()\n",
    "\n",
    "#Generate neuroglancer link to visually rvaluate the presence of other Tm9s\n",
    "url = flywire.encode_url(post_id_ls)\n",
    "print(f'Postynaptic segments: {url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Existing\n",
    "Tm9_ids = [720575940624502013,\n",
    "720575940617720413,\n",
    "720575940628205800,\n",
    "720575940631746090,\n",
    "720575940633161005,\n",
    "720575940622801366,\n",
    "720575940619775281,\n",
    "720575940612306650,\n",
    "720575940622355226]\n",
    "\n",
    "new_Tm9_ids_df = flywire.update_ids(Tm9_ids, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flywire.encode_url(Tm9_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Tm9_ids_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "55c4d5a31b5732887a8ae1b8e753e31c6845ae1153dd13126928af3876e534ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fbbfb0d",
   "metadata": {},
   "source": [
    "# Updating a proofreading table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355cfd2",
   "metadata": {},
   "source": [
    "This notebook contains functions and example scripts to update a proofreading table stored in an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e090bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fafbseg import flywire\n",
    "from caveclient import CAVEclient\n",
    "\n",
    "client = CAVEclient('flywire_fafb_production')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0ec97",
   "metadata": {},
   "source": [
    "## A) Updating IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4beeb",
   "metadata": {},
   "source": [
    "### 1. Loading Tm9 input neuron table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15183aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose path and file\n",
    "dataPath = r'C:\\Users\\sebas\\Downloads'\n",
    "fileName = 'All_Tm9_neurons_input_count_ME_R_20230102.xlsx'\n",
    "filePath = os.path.join(dataPath,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading file as DataFrame\n",
    "df = pd.read_excel(filePath)\n",
    "if df[\"seg_id\"][0] == 'asdf': #Dropping the fisrt row ('asdf' was added as a walk-around to set that column values as type str)\n",
    "    df = df.iloc[1: , :]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "display(df.head(1))\n",
    "segmentIDs = df[\"seg_id\"]\n",
    "pre_IDs = df[\"presynaptic_ID\"]\n",
    "post_IDs = df[\"postsynaptic_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66906b",
   "metadata": {},
   "source": [
    "### 2. Updating IDs in a for loop t oconsider excel file extreucture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25de4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating segments (SLOW)\n",
    "new_segmentIDs_column = []\n",
    "confidence_of_update = []\n",
    "count = 1\n",
    "for id in pre_IDs:\n",
    "    count =+ 1\n",
    "    if id == 'INPUTS PROOFREAD':\n",
    "        new_segmentIDs_column.append('INPUTS PROOFREAD')\n",
    "        confidence_of_update.append('INPUTS PROOFREAD')\n",
    "    else:\n",
    "        temp_segmentIDs_df = flywire.update_ids(id, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "        new_segmentIDs_column.append(str(temp_segmentIDs_df[\"new_id\"][0]))\n",
    "        confidence_of_update.append(temp_segmentIDs_df[\"confidence\"][0])\n",
    "    print(f'row: {count} {new_segmentIDs_column[-1]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(confidence_of_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7988dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Updating the dataframe\n",
    "# Adding the new url column to the data frame\n",
    "df[\"Updated_seg_id\"] = new_segmentIDs_column\n",
    "df[\"Updated_seg_id\"] = df[\"Updated_seg_id\"].astype(str) \n",
    "df[\"Update_confidence\"] = confidence_of_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1db6679",
   "metadata": {},
   "source": [
    "### 3. Saving back to the excell file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating string for the date\n",
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "date_str = x.strftime(\"%d\") + x.strftime(\"%b\") + x.strftime(\"%Y\")\n",
    "\n",
    "# Writting in an existing excel file\n",
    "from openpyxl import load_workbook\n",
    "book = load_workbook(filePath)\n",
    "writer = pd.ExcelWriter(filePath, engine = 'openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "df.to_excel(writer, sheet_name='Updated_IDs_'+date_str)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b26163",
   "metadata": {},
   "source": [
    "### 3. Or, saving in a new excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55348263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving in a new file\n",
    "\n",
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "date_str = x.strftime(\"%d\") + x.strftime(\"%b\") + x.strftime(\"%Y\")\n",
    "\n",
    "file_name = f'All_Tm9_neurons_input_count_segments_update_{date_str}.xlsx'\n",
    "savePath = os.path.join(dataPath, file_name)\n",
    "df.to_excel(savePath, sheet_name='Segments update')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b1975",
   "metadata": {},
   "source": [
    "### Faster update (code in progress...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4efa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating segments (FAST)\n",
    "#Do all segments as once, but filter out columns with 'INPUTS PROOFREAD' first\n",
    "filtered_df = df[df[\"presynaptic_ID\"] =! 'INPUTS PROOFREAD'].copy()\n",
    "segmentIDs = filtered_df[\"seg_id\"]\n",
    "pre_IDs = filtered_df[\"presynaptic_ID\"]\n",
    "post_IDs = filtered_df[\"postsynaptic_ID\"]\n",
    "\n",
    "new_segmentIDs_df = flywire.update_ids(segmentIDs, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "new_segmentIDs = new_segmentIDs_df[\"new_id\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f447f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Updating the dataframe\n",
    "# Adding the new url column to the data frame\n",
    "filtered_df[\"Updated_seg_id\"] = new_segmentIDs\n",
    "filtered_df[\"Updated_seg_id\"] = filtered_df[\"Updated_seg_id\"].astype(str) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d77f535",
   "metadata": {},
   "source": [
    "### 1. Loading another dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9371beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose path and file\n",
    "dataPath = r'C:\\Users\\sebas\\Downloads'\n",
    "fileName = 'Tm9 proofreadings_20221229.xlsx'\n",
    "fileName = 'Tm1 proofreadings_20230105.xlsx'\n",
    "filePath = os.path.join(dataPath,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc1b0994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>XYZ</th>\n",
       "      <th>voxel_raw_x</th>\n",
       "      <th>voxel_raw_y</th>\n",
       "      <th>voxel_raw_z</th>\n",
       "      <th>symbol</th>\n",
       "      <th>hemisphere</th>\n",
       "      <th>lab</th>\n",
       "      <th>author</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>lab authorship (Y/N)</th>\n",
       "      <th>inputs_proofread (Y/N)</th>\n",
       "      <th>notes</th>\n",
       "      <th>annotations_link</th>\n",
       "      <th>Extra notes (see comments)</th>\n",
       "      <th>Working on</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>patch_id</th>\n",
       "      <th>twigs proofread (Y/N)</th>\n",
       "      <th>paired_Tm9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45301, 58147, 5917</td>\n",
       "      <td>48257, 57194, 5249</td>\n",
       "      <td>48257.0</td>\n",
       "      <td>57194.0</td>\n",
       "      <td>5249.0</td>\n",
       "      <td>Tm1</td>\n",
       "      <td>R</td>\n",
       "      <td>Marion Silies</td>\n",
       "      <td>Annalena Oswald</td>\n",
       "      <td>Transmedullary neuron 1, Tm1, Tm1_R,  FBbt_000...</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ngl.flywire.ai/?local_id=ea7026658a0da...</td>\n",
       "      <td>merges to check (mi) checked (BG)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>720575940624502013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48378, 75605, 5574</td>\n",
       "      <td>56469, 74237, 5502</td>\n",
       "      <td>56469.0</td>\n",
       "      <td>74237.0</td>\n",
       "      <td>5502.0</td>\n",
       "      <td>Tm1</td>\n",
       "      <td>R</td>\n",
       "      <td>Greg Jefferis, Marion Silies</td>\n",
       "      <td>Arti Yadav, Annalena Oswald</td>\n",
       "      <td>Transmedullary neuron 1, Tm1, Tm1_R,  FBbt_000...</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ngl.flywire.ai/?json_url=https://globa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Annalena</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>720575940613521635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62332, 93823, 5176</td>\n",
       "      <td>68122, 86392, 5321</td>\n",
       "      <td>68122.0</td>\n",
       "      <td>86392.0</td>\n",
       "      <td>5321.0</td>\n",
       "      <td>Tm1</td>\n",
       "      <td>R</td>\n",
       "      <td>Marion Silies, Mala Murthy, Sebastian Seung</td>\n",
       "      <td>Annalena Oswald, Nash Hadjerol</td>\n",
       "      <td>Transmedullary neuron 1, Tm1, Tm1_R,  FBbt_000...</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ngl.flywire.ai/?json_url=https://globa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>720575940620703936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46174, 62535, 5673</td>\n",
       "      <td>53993, 60454, 5460</td>\n",
       "      <td>53993.0</td>\n",
       "      <td>60454.0</td>\n",
       "      <td>5460.0</td>\n",
       "      <td>Tm1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transmedullary neuron 1, Tm1, Tm1_R,  FBbt_000...</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ngl.flywire.ai/?json_url=https://globa...</td>\n",
       "      <td>two merges to check (mi); done (LL)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>720575940628205800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45236, 57783, 5504</td>\n",
       "      <td>54511, 56401, 5424</td>\n",
       "      <td>54511.0</td>\n",
       "      <td>56401.0</td>\n",
       "      <td>5424.0</td>\n",
       "      <td>Tm1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transmedullary neuron 1, Tm1, Tm1_R,  [FBbt_00...</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ngl.flywire.ai/?json_url=https://globa...</td>\n",
       "      <td>merges to check (mi); checked but still 2 that...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>720575940612306650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1.0                 XYZ  voxel_raw_x  voxel_raw_y  \\\n",
       "0  45301, 58147, 5917  48257, 57194, 5249      48257.0      57194.0   \n",
       "1  48378, 75605, 5574  56469, 74237, 5502      56469.0      74237.0   \n",
       "2  62332, 93823, 5176  68122, 86392, 5321      68122.0      86392.0   \n",
       "3  46174, 62535, 5673  53993, 60454, 5460      53993.0      60454.0   \n",
       "4  45236, 57783, 5504  54511, 56401, 5424      54511.0      56401.0   \n",
       "\n",
       "   voxel_raw_z symbol hemisphere  \\\n",
       "0       5249.0    Tm1          R   \n",
       "1       5502.0    Tm1          R   \n",
       "2       5321.0    Tm1          R   \n",
       "3       5460.0    Tm1          R   \n",
       "4       5424.0    Tm1          R   \n",
       "\n",
       "                                            lab  \\\n",
       "0                                 Marion Silies   \n",
       "1                  Greg Jefferis, Marion Silies   \n",
       "2  Marion Silies, Mala Murthy, Sebastian Seung    \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "                            author  \\\n",
       "0                 Annalena Oswald    \n",
       "1     Arti Yadav, Annalena Oswald    \n",
       "2  Annalena Oswald, Nash Hadjerol    \n",
       "3                              NaN   \n",
       "4                              NaN   \n",
       "\n",
       "                                                name  ...  \\\n",
       "0  Transmedullary neuron 1, Tm1, Tm1_R,  FBbt_000...  ...   \n",
       "1  Transmedullary neuron 1, Tm1, Tm1_R,  FBbt_000...  ...   \n",
       "2  Transmedullary neuron 1, Tm1, Tm1_R,  FBbt_000...  ...   \n",
       "3  Transmedullary neuron 1, Tm1, Tm1_R,  FBbt_000...  ...   \n",
       "4  Transmedullary neuron 1, Tm1, Tm1_R,  [FBbt_00...  ...   \n",
       "\n",
       "   lab authorship (Y/N) inputs_proofread (Y/N) notes  \\\n",
       "0                     Y                    NaN   NaN   \n",
       "1                     Y                    NaN   NaN   \n",
       "2                     Y                    NaN   NaN   \n",
       "3                     Y                    NaN   NaN   \n",
       "4                     Y                    NaN   NaN   \n",
       "\n",
       "                                    annotations_link  \\\n",
       "0  https://ngl.flywire.ai/?local_id=ea7026658a0da...   \n",
       "1  https://ngl.flywire.ai/?json_url=https://globa...   \n",
       "2  https://ngl.flywire.ai/?json_url=https://globa...   \n",
       "3  https://ngl.flywire.ai/?json_url=https://globa...   \n",
       "4  https://ngl.flywire.ai/?json_url=https://globa...   \n",
       "\n",
       "                          Extra notes (see comments) Working on cluster_id  \\\n",
       "0                  merges to check (mi) checked (BG)        NaN        2.0   \n",
       "1                                                NaN  Annalena         1.0   \n",
       "2                                                NaN        NaN        0.0   \n",
       "3               two merges to check (mi); done (LL)         NaN        2.0   \n",
       "4  merges to check (mi); checked but still 2 that...        NaN        2.0   \n",
       "\n",
       "  patch_id  twigs proofread (Y/N)          paired_Tm9  \n",
       "0      3.0                      N  720575940624502013  \n",
       "1      2.0                      N  720575940613521635  \n",
       "2      1.0                      N  720575940620703936  \n",
       "3      3.0                      N  720575940628205800  \n",
       "4      3.0                      N  720575940612306650  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loading file as DataFrame\n",
    "df = pd.read_excel(filePath)\n",
    "if df[\"seg_id\"][0] == 'asdf': #Dropping the fisrt row ('asdf' was added as a walk-around to set that column values as type str)\n",
    "    df = df.iloc[1: , :]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "display(df.head())\n",
    "segmentIDs = df[\"seg_id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61e9ba",
   "metadata": {},
   "source": [
    "### 2. Update with CAVE (not preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update IDs witth chunkedgraph module of CAVE\n",
    "\n",
    "# For \"segmentsIDs\"\n",
    "#Empty spaces are type float and will be filled with \"0\"\n",
    "segmentsIDs_int = list(map(lambda x: 0 if type(x) == float else int(x),segmentIDs)) # From str to int\n",
    "#to create a np.zeros array is important for the next step\n",
    "new_segmentsIDs_int = list(map(lambda x: np.zeros(1) if x == 0 else client.chunkedgraph.get_latest_roots(x),segmentsIDs_int))\n",
    "#Updated IDs leading to more than one ID a single ID will be kept inside [] brakets.\n",
    "new_segmentsIDs_str = list(map(lambda x: str(x[0]) if x.size == 1 else x,new_segmentsIDs_int)) # From int to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"pre_IDs\"\n",
    "#Empty spaces are type float and will be filled with \"0\"\n",
    "pre_IDs_int = list(map(lambda x: 0 if type(x) == float or x == 'INPUTS PROOFREAD'  else int(x),pre_IDs)) # From str to int\n",
    "#to create a np.zeros array is important for the next step\n",
    "new_pre_IDs_int = list(map(lambda x: np.zeros(1) if x == 0 else client.chunkedgraph.get_latest_roots(x),pre_IDs_int))\n",
    "#Updated IDs leading to more than one ID a single ID will be kept inside [] brakets.\n",
    "new_pre_IDs_str = list(map(lambda x: str(x[0]) if x.size == 1 else x,new_pre_IDs_int)) # From int to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"post_IDs\"\n",
    "#Empty spaces are type float and will be filled with \"0\"\n",
    "post_IDs_int = list(map(lambda x: 0 if type(x) == float else int(x),post_IDs)) # From str to int\n",
    "#to create a np.zeros array is important for the next step\n",
    "new_post_IDs_int = list(map(lambda x: np.zeros(1) if x == 0 else client.chunkedgraph.get_latest_roots(x),post_IDs_int))\n",
    "#Updated IDs leading to more than one ID a single ID will be kept inside [] brakets.\n",
    "new_post_IDs_str = list(map(lambda x: str(x[0]) if x.size == 1 else x,new_post_IDs_int)) # From int to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seleting the right pre_ID if the update gaves more than one\n",
    "#Getting the correct pre_IDs than contact each post_ID\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "correct_IDs = {}\n",
    "curr_post_ID = 'Start'\n",
    "for idx,pre_IDs in  enumerate(new_pre_IDs_str):\n",
    "        \n",
    "    #If there are multiple IDs in an array\n",
    "    if type(pre_IDs) != str and type(pre_IDs) == np.ndarray:\n",
    "        #Creatting synapses dataframe only once per each post_ID\n",
    "        if curr_post_ID != new_post_IDs_str[idx]:\n",
    "            synapses = flywire.synapses.fetch_synapses(new_post_IDs_str[idx], pre=False, post=True, attach=True,\n",
    "                                          min_score=50, clean=True, transmitters=False,\n",
    "                                          neuropils=True, batch_size=30,\n",
    "                                          dataset='production', progress=True,mat=\"live\")\n",
    "            #Update post_ID\n",
    "            print(f\"Looking at post_ID: {new_post_IDs_str[idx]}\") \n",
    "            curr_post_ID = new_post_IDs_str[idx]\n",
    "            \n",
    "        #Proof connectivity to the respective post_ID for each of them\n",
    "        for ID in pre_IDs:\n",
    "            if synapses[synapses['pre'] == ID].empty:\n",
    "                continue\n",
    "            else: # Only add the pre_ID (and its index) which has valid synapses with the post_IDs\n",
    "                if idx in correct_IDs.keys(): # If there is already a valid ID, add other valid IDs \n",
    "                    curr_value =correct_IDs[idx]\n",
    "                    new_value = curr_value+\"_\"+str(ID)\n",
    "                    correct_IDs[idx] =new_value\n",
    "                else:\n",
    "                    correct_IDs[idx]=str(ID)\n",
    "\n",
    "# Fixing the updated pre_IDs_str_list\n",
    "for key, value in correct_IDs.items():\n",
    "    new_pre_IDs_str[key] = value\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d9c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Updating the dataframe\n",
    "# Adding the new url column to the data frame\n",
    "df[\"Updated_pre_IDs\"] = new_pre_IDs_str\n",
    "df[\"Updated_post_IDs\"] = new_post_IDs_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df911c6d",
   "metadata": {},
   "source": [
    "### 2. Update with FAFB (predered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94d797c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Updating the segmentIDs\n",
    "new_segmentIDs_df = flywire.update_ids(segmentIDs, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "new_segmentIDs = new_segmentIDs_df[\"new_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "435ee322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_segmentIDs_df[\"confidence\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb93b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Updating the dataframe\n",
    "# Adding the new url column to the data frame\n",
    "df[\"Updated_seg_id\"] = new_segmentIDs\n",
    "df[\"Updated_seg_id\"] = df[\"Updated_seg_id\"].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b6b295d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>XYZ</th>\n",
       "      <th>voxel_raw_x</th>\n",
       "      <th>voxel_raw_y</th>\n",
       "      <th>voxel_raw_z</th>\n",
       "      <th>symbol</th>\n",
       "      <th>hemisphere</th>\n",
       "      <th>lab</th>\n",
       "      <th>author</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>inputs_proofread (Y/N)</th>\n",
       "      <th>notes</th>\n",
       "      <th>annotations_link</th>\n",
       "      <th>Extra notes (see comments)</th>\n",
       "      <th>Working on</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>patch_id</th>\n",
       "      <th>twigs proofread (Y/N)</th>\n",
       "      <th>paired_Tm9</th>\n",
       "      <th>Updated_seg_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [1.0, XYZ, voxel_raw_x, voxel_raw_y, voxel_raw_z, symbol, hemisphere, lab, author, name, seg_id, identified_in, lab authorship (Y/N), inputs_proofread (Y/N), notes, annotations_link, Extra notes (see comments), Working on, cluster_id, patch_id, twigs proofread (Y/N), paired_Tm9, Updated_seg_id]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Updated_seg_id\"].duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d28c33e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_id</th>\n",
       "      <th>new_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>720575940613143574</td>\n",
       "      <td>720575940623515597</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>720575940627285447</td>\n",
       "      <td>720575940627285447</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>720575940630078330</td>\n",
       "      <td>720575940630078330</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>720575940633718041</td>\n",
       "      <td>720575940633718041</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>720575940629908730</td>\n",
       "      <td>720575940629908730</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>720575940612397226</td>\n",
       "      <td>720575940612397226</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>720575940631366968</td>\n",
       "      <td>720575940660576385</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               old_id              new_id  confidence  changed\n",
       "0  720575940613143574  720575940623515597           1     True\n",
       "1  720575940627285447  720575940627285447           1    False\n",
       "2  720575940630078330  720575940630078330           1    False\n",
       "3  720575940633718041  720575940633718041           1    False\n",
       "4  720575940629908730  720575940629908730           1    False\n",
       "5  720575940612397226  720575940612397226           1    False\n",
       "6  720575940631366968  720575940660576385           1     True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_segmentIDs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271c1dff",
   "metadata": {},
   "source": [
    "### 3. Reorder rows base don condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by = 'cluster_id').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c37a7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "140c3852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    720575940623515597\n",
       "1    720575940627285447\n",
       "2    720575940630078330\n",
       "3    720575940633718041\n",
       "4    720575940629908730\n",
       "5    720575940612397226\n",
       "6    720575940660576385\n",
       "Name: Updated_seg_id, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Updated_seg_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2491c222",
   "metadata": {},
   "source": [
    "### 4. Saving back to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2c3d919",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23256\\3706219640.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Writting in an existing excel file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopenpyxl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_workbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'openpyxl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EM\\lib\\site-packages\\openpyxl\\reader\\excel.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(filename, read_only, keep_vba, data_only, keep_links)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[0;32m    315\u001b[0m     reader = ExcelReader(filename, read_only, keep_vba,\n\u001b[1;32m--> 316\u001b[1;33m                         data_only, keep_links)\n\u001b[0m\u001b[0;32m    317\u001b[0m     \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EM\\lib\\site-packages\\openpyxl\\reader\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fn, read_only, keep_vba, data_only, keep_links)\u001b[0m\n\u001b[0;32m    122\u001b[0m     def __init__(self,  fn, read_only=False, keep_vba=KEEP_VBA,\n\u001b[0;32m    123\u001b[0m                   data_only=False, keep_links=True):\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marchive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_archive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marchive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_only\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EM\\lib\\site-packages\\openpyxl\\reader\\excel.py\u001b[0m in \u001b[0;36m_validate_archive\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidFileException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0marchive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marchive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EM\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[0;32m   1223\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1226\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m                 \u001b[1;31m# set the modified flag so central directory gets written\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EM\\lib\\zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File is not a zip file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File is not a zip file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating string for the date\n",
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "date_str = x.strftime(\"%d\") + x.strftime(\"%b\") + x.strftime(\"%Y\")\n",
    "\n",
    "# Writting in an existing excel file\n",
    "from openpyxl import load_workbook\n",
    "book = load_workbook(filePath)\n",
    "writer = pd.ExcelWriter(filePath, engine = 'openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "sorted_df.to_excel(writer, sheet_name='Updated_IDs_'+date_str)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ad439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
